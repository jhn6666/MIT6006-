{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison model:假设算法只能通过比较来区分项目\n",
    "在该模型下，项目之间的可比性通过以下比较操作进行表示：\n",
    "\n",
    "    小于 (<)\n",
    "    小于等于 (≤)\n",
    "    大于 (>)\n",
    "    大于等于 (≥)\n",
    "    等于 (=)\n",
    "    不等于 (≠)\n",
    "\n",
    "这些比较操作的输出是二进制结果：True（真）或 False（假）。\n",
    "\n",
    "目标：存储一组 n 个可比较项目，并支持 find(k) 操作。\n",
    "\n",
    "在该模型中，算法的运行时间由执行的比较操作数量决定，因此我们需要计算比较操作的数量。\n",
    "\n",
    "对于存储项目可以使用的数据结构，这里没有给出具体说明。常见的数据结构包括列表、树和堆等，具体的选择取决于问题的要求和约束。\n",
    "\n",
    "对于 find(k) 操作，我们可以使用二分搜索算法来快速找到第 k 小或第 k 大的项目。该算法通过重复应用比较操作并根据比较结果缩小搜索范围，以找到目标项目。\n",
    "\n",
    "在这个模型中，性能度量最常用的是比较操作的数量，因为这是算法运行时间的下界。可以通过计数比较操作的次数来评估算法的效率，并与其他算法进行比较。\n",
    "\n",
    "Decision tree:\n",
    "任何算法都可以被视为一个操作执行的决策树。决策树的内部节点表示二进制比较，分支可能为True或False。对于一个比较算法，决策树是二叉的。叶节点表示算法的终止，产生算法的输出。根到叶子的路径表示对某个输入执行算法。至少需要n + 1个叶子节点以满足每个算法输出的需求，所以搜索要求至少需要n + 1个叶子。\n",
    "\n",
    "下面是决策树模型的详细解释：\n",
    "\n",
    "    决策树：决策树由内部节点和叶子节点组成。内部节点表示进行二进制比较的操作，其中包含一个条件判断来决定下一步的分支。叶子节点表示算法的终止，并给出算法的输出。\n",
    "\n",
    "    算法执行路径：从根节点到叶子节点的路径表示算法在某个输入上的执行过程。路径上的内部节点表示算法中的比较操作，根据比较的结果选择不同的分支。\n",
    "\n",
    "    叶子节点和算法输出：每个算法的输出对应至少一个叶子节点。当算法执行到达某个特定的叶子节点时，该叶子节点给出算法的输出结果。\n",
    "\n",
    "    搜索算法：为了满足至少n + 1个算法输出的需求，决策树模型需要至少n + 1个叶子节点。对于搜索算法，除了满足输出需求之外，还可能增加额外的叶子节点来实现不同的搜索需求，增加算法的灵活性。\n",
    "\n",
    "决策树模型提供了一种了解算法执行和判断算法效率的框架。通过分析决策树的结构和执行路径，可以深入了解算法的工作原理和特点，并通过添加或修改节点来优化算法的性能。\n",
    "\n",
    "Comparison Search Lower bound\n",
    "在比较搜索算法中，最坏情况下的运行时间受到一些限制，可以通过以下方式进行界定：\n",
    "\n",
    "    运行时间 ≥ 比较数量 ≥ 最长的根到叶子节点路径的长度 ≥ 树的高度\n",
    "\n",
    "关于二叉树的最小高度和搜索算法的运行时间下界的知识:\n",
    "\n",
    "任意二叉树上至少包含 n 个节点的最小高度是当二叉树是完全二叉树时。完全二叉树的定义是除了最后一层之外的所有层都是满的（即每个节点都有两个子节点），并且最后一层从左到右有可能有部分缺失。\n",
    "\n",
    "\n",
    "\n",
    "    有序数组实现了这个下界。这意味着，对于比较排序算法而言，在最坏情况下，它们无法比 Ω(logn) 更快地对数组进行排序。\n",
    "\n",
    "    更一般地说，当一个具有 Θ(n) 个叶子节点和最大分支因子 b 的树的高度为 Ω(logb n)。\n",
    "\n",
    "要实现更快速的搜索，需要一种操作，它允许超过常数级的分支因子 ω(1)。这是如何实现的呢？\n",
    "\n",
    "一种方法是使用非比较性的搜索算法，如散列（哈希）算法。散列算法通过将关键字映射到数组的索引来快速地查找数据，而不是进行比较操作。散列算法具有平均常数时间复杂度，因为它不需要基于比较来进行搜索。\n",
    "\n",
    "另一种方法是使用一些特殊的数据结构，如树状数组（Binary Indexed Tree）或线段树（Segment Tree）。这些数据结构利用树形结构，并通过使用合适的操作来实现更高的分支因子和更快的查询速度。\n",
    "\n",
    "总结：对于比较搜索算法而言，最坏情况下的运行时间下界是 Ω(log n)，可以通过使用非比较性算法或具有超过常数级分支因子的高级数据结构来实现更快的搜索。\n",
    "\n",
    "Direct Access Array:\n",
    "利用 Word-RAM O(1) 时间的随机访问索引的特性，通过一种直接映射的方式来存储和访问项目。\n",
    "下面是相应的详细解释：\n",
    "\n",
    "    想法：为每个项目分配一个唯一的整数键 k（0 到 u-1 的范围），然后将该项目存储在数组的索引 k 处。\n",
    "    将数组的索引与意义相关联。可以根据索引的值直接访问和操作数组中对应的元素。\n",
    "    如果键可以适应机器字（machine word），即 u ≤ 2^w，其中 w 是机器字的位数，则在最坏情况下可以实现 O(1) 的查找和动态操作效率。\n",
    "    在计算机内存中，任何内容都可以表示为二进制整数，或者使用静态的 64 位内存地址来表示。\n",
    "    然而，直接访问数组的空间复杂度为 O(u)，这意味着如果 n（项目的数量）大于 u（键的取值范围），则空间需求会非常高。\n",
    "\n",
    "举个例子来说明，在键是十个字母大小的名称的情况下，如果每个名称只需要一个位来表示，那么需要大约 2^61 ≈ 17.6 TB 的空间。\n",
    "\n",
    "那么如何使用更少的空间呢？\n",
    "\n",
    "    一种方法是使用哈希表或其他压缩技术。通过哈希函数将键映射到更小的空间范围，并在压缩后的空间中存储项目。这样可以减少空间需求，但可能会引入哈希冲突。\n",
    "    另一种方法是使用有限空间的数据结构，如布隆过滤器（Bloom Filter）或稀疏矩阵（Sparse Matrix）。这些数据结构利用特殊的编码方式来节省空间，并通过牺牲一定的准确性或精确性来达到更小的空间需求。\n",
    "\n",
    "需要根据具体情况和需求选择合适的方法来降低空间要求。在使用 Direct Access Array 时，确保键的取值范围 u 足够大，以适应需要存储的项目数量 n，同时考虑使用压缩技术来降低空间使用量。\n",
    "\n",
    "Hashing:通过将键映射到较小的范围并使用较小的直接访问数组来减少空间需求（如果n小于u）。\n",
    "下面是关于哈希的详细解释：\n",
    "\n",
    "    想法：如果项目的数量 n 小于等于键的取值范围 u，将键映射到较小的范围 m = Θ(n)，并使用较小的直接访问数组。这样可以减小空间需求。\n",
    "\n",
    "    哈希函数：哈希函数 h(k)：{0, . . . , u-1} → {0, . . . , m-1}（也称为哈希映射）。通过哈希函数将键映射为较小范围的索引，用于访问和存储相关数据。\n",
    "\n",
    "    直接访问数组被称为哈希表，而 h(k) 被称为键 k 的哈希值。\n",
    "\n",
    "    如果 m 小于等于 u，根据鸽笼原理，不存在一种哈希函数是单射的。总能找到两个键 a 和 b，使得 h(a) = h(b)，这就是所谓的哈希冲突。\n",
    "\n",
    "    由于无法将两个键存储在同一索引处，我们需要决定在哪里存储冲突的项目。可以有两种常见的方法：\n",
    "        开放地址法（open addressing）：将冲突项目存储在哈希表的其他位置。这种方法的分析比较复杂，但在实际中很常见。\n",
    "        链接法（chaining）：将冲突项目存储在另一个支持动态集合接口的数据结构中。例如，可以使用链表或数组等数据结构来存储冲突项目。\n",
    "需要考虑一些因素来选择适合的哈希函数和处理冲突的方法，包括键的分布特征、数据访问模式和性能要求。\n",
    "\n",
    "总结：在哈希中，通过哈希函数将键映射到较小的范围，以减少空间需求。因为哈希函数无法保证完全避免冲突，所以我们需要采用适当的方法来处理冲突，如开放地址法或链接法。选择合适的哈希函数和处理冲突的方法对于实现高效的哈希算法非常重要。\n",
    "\n",
    "Chaining(链接法):\n",
    "在哈希（Hashing）中，存在一定概率的键冲突，即不同的键可能被哈希函数映射到相同的索引位置，这被称为哈希冲突。因为无法将两个项目存储在同一索引处，所以我们需要考虑如何处理冲突。其中两种常见的方法是开放地址法和链接法（chaining）。\n",
    "\n",
    "在链接法中的处理方式如下：\n",
    "\n",
    "    想法：将冲突的项目存储在另一个数据结构中，通常是链表。每个索引位置都维护一个链表，将冲突的项目链接在一起。\n",
    "\n",
    "    如果键在索引位置上分布均匀，链长度为 n/m，其中 n 是项目数量，m 是哈希表的大小。那么链的大小为 n/Ω(n) = O(1)。在这种情况下，所有操作的时间复杂度为 O(1)，因为链表的长度是常数级别的。\n",
    "\n",
    "    但是，如果许多项目映射到相同的索引位置，例如 h(k) = 常数，那么链的长度可能为 Θ(n)，即线性级别的。这将导致较差的性能。\n",
    "\n",
    "    为了实现较好的性能，需要使用良好的哈希函数。好的哈希函数应该尽可能将键均匀地映射到哈希表的索引位置，减少冲突的概率。良好的哈希函数应该具有以下特性：\n",
    "        均匀性：将键均匀地分布在哈希表的索引位置上。\n",
    "        独立性：不同的键应该独立地影响哈希值，以避免聚集效应。\n",
    "\n",
    "选择合适的哈希函数对于实现高效的哈希算法非常重要。常用的哈希函数设计方法包括除法取余法、乘法取整法、平方取中法等。选择适合具体应用场景和键分布特点的哈希函数可以提高性能和减少冲突的发生概率。\n",
    "\n",
    "总结：在链接法中，冲突的项目通过链接形成链表，存储在另一个数据结构中。使用良好的哈希函数可以减少冲突的发生概率，提高性能。良好的哈希函数应该具有均匀性和独立性，将键均匀地映射到哈希表的索引位置上。\n",
    "\n",
    "Hash Function(选择一个适合的哈希函数来将键映射到哈希表的索引位置):\n",
    "\n",
    "\n",
    "    除法方法（Division）：例如，使用 h(k) = (k mod m) 的方式进行哈希。这是一种启发式的方法，在键均匀分布的情况下效果良好。选择合适的 m 值可以避免键的对称性。通常，选择远离2的幂次和10的幂次的大素数作为 m 是合理的。Python 在此基础上进行了一些额外的混合操作。\n",
    "\n",
    "    如果键的数量 u 大于哈希表大小 n，那么无论使用哪种哈希函数，都会有某个输入集合会导致 O(n) 大小的链表。这是因为根据鸽笼原理，要确保每个键都有一个唯一索引是不可能的。\n",
    "\n",
    "    想法！不要使用固定的哈希函数！而是随机选择一个哈希函数（但需要谨慎选择）。通过随机选择哈希函数，可以避免特定输入集合导致较大的冲突。我们可以在哈希表创建时随机选择一个哈希函数，或者使用通用的哈希函数族（universal hash functions）。\n",
    "\n",
    "    通用的哈希函数族是一组具有随机性质的哈希函数，通过从该族中随机选择一个哈希函数来处理冲突。这样，即使在最坏情况下，也可以避免特定输入集合导致长链的问题。常见的通用哈希函数族包括乘法哈希和双重哈希等。\n",
    "\n",
    "纵观哈希函数的选择，避免使用固定的哈希函数并随机选择一个哈希函数是一种常见的策略，它可以有效地减少冲突的发生概率并提高哈希表的性能。\n",
    "\n",
    "总结：在选择哈希函数时，除了传统的除法方法，还可以选择随机的哈希函数，或者使用通用的哈希函数族。通过随机选择哈希函数，我们可以减少冲突的发生概率，并避免特定输入集合导致的长链问题。选择合适的哈希函数对于实现高效的哈希算法非常重要。\n",
    "\n",
    "    通用方法（Universal Hash Functions）:是一种很有用且理论上良好的哈希函数。下面对通用哈希函数族进行详细解释，并给出相应的公式：\n",
    "\n",
    "    通用哈希函数定义：hab(k) = (((ak + b) mod p) mod m)，其中 a 和 b 是来自 {0, . . . , p-1} 范围的参数，且 a ≠ 0。p 是一个大于 u 的素数，m 是哈希表的大小。\n",
    "\n",
    "    哈希函数族 H(p, m) = {hab | a, b ∈ {0, . . . , p-1} and a ≠ 0} 是由一组具体的参数 a、b、p 定义的哈希函数集合。\n",
    "\n",
    "    通用哈希函数族的特性：对于任意的不相等的 ki 和 kj，都有 Pr {h(ki) = h(kj)} ≤ 1/m，其中 h ∈ H。\n",
    "\n",
    "    为什么通用哈希函数族很有用？因为它能够保证较短的链长（在期望意义下）。\n",
    "\n",
    "    定义指示随机变量 Xij，表示 h ∈ H 情况下是否存在 h(ki) = h(kj)。如果 h(ki) = h(kj)，则 Xij = 1，否则 Xij = 0。\n",
    "\n",
    "    索引 h(ki) 处链的长度是随机变量 Xi，定义为：Xi = ΣXij，其中 j 遍历 {0, . . . , u-1} 且 j ≠ i。\n",
    "\n",
    "    索引 h(ki) 处链的期望长度为：\n",
    "    E[Xi] = E[ΣXij] = ΣE[Xij] (由线性性质) = 1 + E[Xij] (因为 j ≠ i 时 E[Xij] = 0)\n",
    "\n",
    "    根据通用哈希函数的特性，Pr {h(ki) = h(kj)} ≤ 1/m，所以期望长度的上界为：\n",
    "    E[Xi] ≤ 1 + 1/m = 1 + (n - 1)/m\n",
    "\n",
    "    由于 m = Ω(n)，负载因子 α = n/m = O(1)，因此期望长度为 O(1)。\n",
    "\n",
    "总结：通用哈希函数族通过随机选择哈希函数，保证了较短的链长。利用通用哈希函数族的特性，我们可以得出在期望意义下，索引位置处链的长度为 O(1)。这对于实现高效的哈希算法非常有益。\n",
    "\n",
    "\n",
    "    Dynamic:\n",
    "    在动态哈希表中，如果元素数量与哈希表大小的比例（n/m）远离1，我们可以选择重新构建哈希表，并使用新的随机选择的哈希函数。\n",
    "\n",
    "    以下是对动态哈希表的更详细解释：\n",
    "\n",
    "        如果哈希表的负载因子（元素数量除以哈希表大小的比值）接近1，即 n/m 接近1，可以选择重新构建哈希表。重新构建的过程包括选择新的随机哈希函数以及调整哈希表的大小。\n",
    "\n",
    "        与动态数组类似，我们可以将重新构建哈希表的成本分摊到多次动态操作中进行分析。这意味着即使重新构建哈希表的成本较高，也可以通过多次操作的平摊成本来达到高效的性能。\n",
    "\n",
    "        因此，一个动态哈希表可以以期望的均摊 O(1) 时间复杂度实现动态集合操作。\n",
    "\n",
    "    总结：动态哈希表允许在哈希表元素数量发生变化时进行动态调整，以保持高效性能。通过重新构建哈希表和选择新的随机哈希函数，可以将每个操作的成本均摊到多次动态操作中，从而实现期望的均摊 O(1) 的时间复杂度。这使得哈希表成为一种强大的数据结构，可以在实际应用中高效地支持动态集合操作。\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
